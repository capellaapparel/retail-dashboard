# ==========================================
# File: pages/9_ì˜µì…˜_ì¹´í…Œê³ ë¦¬_ë¶„ì„.py
# ==========================================
import streamlit as st
import pandas as pd
import re
from dateutil import parser

st.set_page_config(page_title="ì˜µì…˜/ì¹´í…Œê³ ë¦¬ ë¶„ì„", layout="wide")
st.title("ğŸ§© ì˜µì…˜ Â· ì¹´í…Œê³ ë¦¬ ë¶„ì„")

# -------------------------
# Helpers
# -------------------------
@st.cache_data(show_spinner=False)
def load_google_sheet(sheet_name: str) -> pd.DataFrame:
    import gspread
    from oauth2client.service_account import ServiceAccountCredentials
    import json
    GOOGLE_SHEET_URL = "https://docs.google.com/spreadsheets/d/1oyVzCgGK1Q3Qi_sbYwE-wKG6SArnfUDRe7rQfGOF-Eo"
    scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
    creds_json = {k: str(v) for k, v in st.secrets["gcp_service_account"].items()}
    with open("/tmp/service_account.json", "w") as f:
        import json as _json
        _json.dump(creds_json, f)
    creds = ServiceAccountCredentials.from_json_keyfile_name("/tmp/service_account.json", scope)
    client = gspread.authorize(creds)
    ws = client.open_by_url(GOOGLE_SHEET_URL).worksheet(sheet_name)
    df = pd.DataFrame(ws.get_all_records())
    df.columns = [c.lower().strip() for c in df.columns]
    return df

def parse_temudate(x):
    s = str(x)
    if "(" in s:
        s = s.split("(")[0].strip()
    try:
        return parser.parse(s, fuzzy=True)
    except Exception:
        return pd.NaT

def parse_sheindate(x):
    try:
        return pd.to_datetime(str(x), errors="coerce", infer_datetime_format=True)
    except Exception:
        return pd.NaT

def money_series(s: pd.Series) -> pd.Series:
    return pd.to_numeric(s.astype(str).str.replace(r"[^0-9.\-]", "", regex=True), errors="coerce").fillna(0.0)

# ìŠ¤íƒ€ì¼ í‚¤ í†µì¼(ê³µë°± ì œê±° + ëŒ€ë¬¸ì)
def norm_style(s) -> str:
    return str(s).upper().replace(" ", "")

# Size í‘œì¤€í™”(ì£¼ì‹  ë“±ê°€ ë§¤í•‘)
SIZE_MAP = {
    "1XL":"1X","2XL":"2X","3XL":"3X",
    "SMALL":"S","MEDIUM":"M","LARGE":"L",
    "S":"S","M":"M","L":"L","XL":"XL","XXL":"2X","XXXL":"3X","1X":"1X","2X":"2X","3X":"3X"
}

def norm_size(x: str) -> str:
    s = str(x).strip().upper()
    return SIZE_MAP.get(s, s)

def norm_color(x: str) -> str:
    # SHEIN ìƒ‰ìƒì€ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ê³µë°± ëŒ€ì²´ â†’ ë³µì›
    s = str(x).strip().replace("_", " ")
    return s.title()

# ì¹´í…Œê³ ë¦¬ ë§¤í•‘(ê¸°ë³¸: PRODUCT_INFO.length)
TOP_TAGS    = {"crop top","waist top","long top","top"}
DRESS_TAGS  = {"mini dress","midi dress","maxi dress","dress"}
SKIRT_TAGS  = {"mini skirt","midi skirt","maxi skirt","skirt"}
BOTTOM_TAGS = {"shorts","knee","capri","full","pants","bottom"}  # pants/shortsë¥˜

def base_category_from_length(length_val: str) -> str | None:
    s = str(length_val).strip().lower()
    if not s or s in {"nan","none","-"}:
        return None
    if "set" in s:
        return "SET"
    if any(t in s for t in TOP_TAGS):
        return "TOP"
    if any(t in s for t in DRESS_TAGS):
        return "DRESS"
    if any(t in s for t in SKIRT_TAGS):
        return "SKIRT"
    if any(t in s for t in BOTTOM_TAGS):
        # BOTTOMì€ ë’¤ì—ì„œ ROMPER/JUMPSUIT ê°ì§€ë¡œ ì„¸ë¶„í™”
        return "BOTTOM"
    return None

# TEMU product nameì—ì„œ ROMPER/JUMPSUIT ê°ì§€
def refine_bottom_with_name(base_cat: str, name_text: str) -> str:
    if base_cat != "BOTTOM":
        return base_cat
    s = str(name_text).lower()
    if "romper" in s:
        return "ROMPER"
    if "jumpsuit" in s:
        return "JUMPSUIT"
    return "PANTS"   # ê·¸ ì™¸ ë°”í…€ë¥˜ëŠ” PANTSë¡œ

# SHEIN Seller SKU íŒŒì‹±: 'SKU-COLOR-SIZE' (í•˜ì´í”ˆìœ¼ë¡œ êµ¬ë¶„, ì»¬ëŸ¬ëŠ” '_' â†’ ' ')
def parse_shein_sku(sku: str) -> tuple[str,str,str]:
    raw = str(sku)
    parts = raw.split("-")
    if len(parts) >= 3:
        sz  = norm_size(parts[-1])
        col = norm_color("-".join(parts[1:-1]))  # ì»¬ëŸ¬ì— '-'ê°€ í¬í•¨ë  ìˆ˜ ìˆì–´ ì¤‘ê°„ë¶€ í•©ì¹¨
        sty = norm_style(parts[0])
        return sty, col, sz
    # fallback
    return norm_style(raw), "", ""

# -------------------------
# Load sheets
# -------------------------
info  = load_google_sheet("PRODUCT_INFO")
temu  = load_google_sheet("TEMU_SALES")
shein = load_google_sheet("SHEIN_SALES")

# Precompute styleâ†’length/category, image
info["style_key"] = info["product number"].astype(str).map(norm_style)
INFO_LEN_MAP  = dict(zip(info["style_key"], info.get("length","")))
IMG_MAP       = dict(zip(info["style_key"], info.get("image","")))

# -------------------------
# Normalize sales rows
# -------------------------
# TEMU
temu["order date"]  = temu["purchase date"].apply(parse_temudate)
temu["order item status"] = temu["order item status"].astype(str)
temu["quantity shipped"]  = pd.to_numeric(temu.get("quantity shipped", 0), errors="coerce").fillna(0)
if "base price total" in temu.columns:
    temu["base price total"] = money_series(temu["base price total"])

temu["style_key"] = temu["product number"].astype(str).map(norm_style)
temu["color_norm"] = temu.get("color","").astype(str).apply(norm_color)
temu["size_norm"]  = temu.get("size","").astype(str).apply(norm_size)

# SHEIN
shein["order date"] = shein["order processed on"].apply(parse_sheindate)
shein["order status"] = shein["order status"].astype(str)
if "product price" in shein.columns:
    shein["product price"] = money_series(shein["product price"])

# Seller SKU â†’ style/color/size
sty, col, sz = zip(*shein.get("seller sku", "").astype(str).apply(parse_shein_sku))
shein["style_key"] = list(sty)
shein["color_norm"] = list(col)
shein["size_norm"]  = list(sz)

# -------------------------
# Controls
# -------------------------
min_dt = pd.to_datetime(pd.concat([temu["order date"], shein["order date"]]).dropna()).min()
max_dt = pd.to_datetime(pd.concat([temu["order date"], shein["order date"]]).dropna()).max()

c1, c2 = st.columns([1.4,1])
with c1:
    dr = st.date_input(
        "ì¡°íšŒ ê¸°ê°„",
        value=(max_dt.date() - pd.Timedelta(days=29), max_dt.date()),
        min_value=min_dt.date(),
        max_value=max_dt.date(),
    )
    if isinstance(dr, (list, tuple)):
        start, end = dr
    else:
        start, end = dr, dr
    start = pd.to_datetime(start); end = pd.to_datetime(end) + pd.Timedelta(days=1) - pd.Timedelta(seconds=1)
with c2:
    platform = st.radio("í”Œë«í¼", ["BOTH","TEMU","SHEIN"], horizontal=True)

# ê¸°ê°„ & ìƒíƒœ í•„í„°
t = temu[(temu["order date"]>=start)&(temu["order date"]<=end)&
         (temu["order item status"].str.lower().isin(["shipped","delivered"]))].copy()
t["qty"] = t["quantity shipped"]
t["sales"] = t.get("base price total", 0.0)

s = shein[(shein["order date"]>=start)&(shein["order date"]<=end)&
          (~shein["order status"].str.lower().eq("customer refunded"))].copy()
s["qty"] = 1.0
s["sales"] = s.get("product price", 0.0)

# ì„ íƒ í”Œë«í¼ ì ìš©
frames = []
if platform in ["BOTH","TEMU"]:  frames.append(t.assign(platform="TEMU"))
if platform in ["BOTH","SHEIN"]: frames.append(s.assign(platform="SHEIN"))
if not frames:
    st.info("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()
sales_df = pd.concat(frames, ignore_index=True)

# -------------------------
# Category classification per row
# -------------------------
# 1) ê¸°ë³¸: PRODUCT_INFO.length â†’ base category
sales_df["base_cat"] = sales_df["style_key"].map(lambda k: base_category_from_length(INFO_LEN_MAP.get(k, "")))

# 2) TEMU: product nameì—ì„œ ROMPER/JUMPSUIT ê°ì§€í•´ BOTTOM ì„¸ë¶„í™”
name_col = "product name by customer order" if "product name by customer order" in sales_df.columns else ""
if name_col:
    sales_df["cat"] = [
        refine_bottom_with_name(bc, nm) if plat=="TEMU" else (bc if bc!="BOTTOM" else "PANTS")
        for bc, nm, plat in zip(sales_df["base_cat"], sales_df[name_col], sales_df["platform"])
    ]
else:
    # TEMU nameì´ ì—†ìœ¼ë©´ BOTTOM â†’ PANTS ë¡œ
    sales_df["cat"] = sales_df["base_cat"].apply(lambda x: "PANTS" if x=="BOTTOM" else x)

# ì—†ê±°ë‚˜ ë¯¸ë¶„ë¥˜ â†’ OTHER
sales_df["cat"] = sales_df["cat"].fillna("OTHER")

# ì´ë¯¸ì§€ URL
sales_df["image"] = sales_df["style_key"].map(IMG_MAP)

# -------------------------
# Category Summary
# -------------------------
cat_sum = (sales_df.groupby(["platform","cat"])
           .agg(qty=("qty","sum"), sales=("sales","sum"))
           .reset_index())
cat_sum["aov"] = cat_sum.apply(lambda r: (r["sales"]/r["qty"]) if r["qty"]>0 else 0.0, axis=1)

st.subheader("ğŸ“Š ì¹´í…Œê³ ë¦¬ë³„ ì„±ê³¼ ìš”ì•½")
st.dataframe(
    cat_sum.sort_values(["platform","sales"], ascending=[True,False]),
    use_container_width=True,
    hide_index=True
)

# -------------------------
# Top Styles by Category
# -------------------------
st.subheader("ğŸ† ì¹´í…Œê³ ë¦¬ë³„ Top Styles (ë§¤ì¶œìˆœ)")
sel_cats = st.multiselect(
    "ì¹´í…Œê³ ë¦¬ ì„ íƒ",
    options=sorted(cat_sum["cat"].unique().tolist()),
    default=sorted(cat_sum["cat"].unique().tolist())
)

if sel_cats:
    topn = st.slider("Top N", 3, 20, 10, 1)
    filt = sales_df[sales_df["cat"].isin(sel_cats)]

    # ìŠ¤íƒ€ì¼ ë ˆë²¨ ì§‘ê³„
    g = (filt.groupby(["platform","cat","style_key","image"])
         .agg(qty=("qty","sum"), sales=("sales","sum"))
         .reset_index())
    g["aov"] = g.apply(lambda r: (r["sales"]/r["qty"]) if r["qty"]>0 else 0.0, axis=1)

    # ì¹´í…Œê³ ë¦¬Â·í”Œë«í¼ë§ˆë‹¤ Top N
    blocks = []
    for (plat, cat), sub in g.groupby(["platform","cat"]):
        sub2 = sub.sort_values("sales", ascending=False).head(topn).copy()
        sub2.insert(0, "platform", plat)
        sub2.insert(1, "cat", cat)
        blocks.append(sub2)
    if blocks:
        tops = pd.concat(blocks, ignore_index=True)
        # ì¸ë„¤ì¼ í¬ê²Œ í‘œì‹œ
        st.markdown("""
        <style>
        [data-testid="stDataFrame"] img { height: 96px !important; width: 96px !important; object-fit: cover; border-radius: 8px; }
        </style>
        """, unsafe_allow_html=True)
        st.dataframe(
            tops.rename(columns={"style_key":"Style Number","image":"ì´ë¯¸ì§€"}),
            use_container_width=True, hide_index=True,
            column_config={
                "ì´ë¯¸ì§€": st.column_config.ImageColumn("ì´ë¯¸ì§€", width="medium"),
                "qty":    st.column_config.NumberColumn("Qty",    format="%,.0f"),
                "sales":  st.column_config.NumberColumn("Sales",  format="$%,.2f"),
                "aov":    st.column_config.NumberColumn("AOV",    format="$%,.2f"),
            }
        )
    else:
        st.info("ì„ íƒí•œ ì¹´í…Œê³ ë¦¬ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# -------------------------
# ì˜µì…˜(ìƒ‰ìƒ/ì‚¬ì´ì¦ˆ) ë¸Œë ˆì´í¬ë‹¤ìš´ (ì„ íƒ)
# -------------------------
st.subheader("ğŸ¨ ìƒ‰ìƒ Â· ğŸ§µ ì‚¬ì´ì¦ˆ ë¶„í¬ (ì„ íƒ ì¹´í…Œê³ ë¦¬)")
with st.expander("ì—´ê¸°/ë‹«ê¸°", expanded=False):
    opt_cats = st.multiselect(
        "ì¹´í…Œê³ ë¦¬ ì„ íƒ (ì˜µì…˜ ë¶„í¬)",
        options=sorted(cat_sum["cat"].unique().tolist()),
        default=sorted(cat_sum["cat"].unique().tolist())
    )
    if opt_cats:
        opt = sales_df[sales_df["cat"].isin(opt_cats)].copy()
        color_g = (opt.groupby(["platform","color_norm"])
                   .agg(qty=("qty","sum"), sales=("sales","sum"))
                   .reset_index()
                   .sort_values("qty", ascending=False))
        size_g  = (opt.groupby(["platform","size_norm"])
                   .agg(qty=("qty","sum"), sales=("sales","sum"))
                   .reset_index()
                   .sort_values("qty", ascending=False))
        c1, c2 = st.columns(2)
        with c1:
            st.markdown("**ìƒ‰ìƒ ë¶„í¬**")
            st.dataframe(color_g, use_container_width=True, hide_index=True)
        with c2:
            st.markdown("**ì‚¬ì´ì¦ˆ ë¶„í¬**")
            st.dataframe(size_g, use_container_width=True, hide_index=True)

# -------------------------
# Download
# -------------------------
st.download_button(
    "ì¹´í…Œê³ ë¦¬ ìš”ì•½ CSV ë‹¤ìš´ë¡œë“œ",
    data=cat_sum.to_csv(index=False),
    file_name="category_summary.csv",
    mime="text/csv",
)
