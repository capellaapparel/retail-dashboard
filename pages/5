# ==========================================
# File: pages/5_êµì°¨í”Œë«í¼_ë¹„êµ.py
# ==========================================
import streamlit as st
import pandas as pd
import re
from dateutil import parser

# -------------------------
# Page Config
# -------------------------
st.set_page_config(page_title="êµì°¨ í”Œë«í¼ ë¹„êµ", layout="wide")
st.title("ğŸ” êµì°¨ í”Œë«í¼ ì„±ê³¼ ë¹„êµ (TEMU vs SHEIN)")

# -------------------------
# Helpers
# -------------------------
@st.cache_data(show_spinner=False)
def load_google_sheet(sheet_name: str) -> pd.DataFrame:
    import gspread
    from oauth2client.service_account import ServiceAccountCredentials
    import json
    GOOGLE_SHEET_URL = "https://docs.google.com/spreadsheets/d/1oyVzCgGK1Q3Qi_sbYwE-wKG6SArnfUDRe7rQfGOF-Eo"
    scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
    creds_json = {k: str(v) for k, v in st.secrets["gcp_service_account"].items()}
    with open("/tmp/service_account.json", "w") as f:
        import json as _json
        _json.dump(creds_json, f)
    creds = ServiceAccountCredentials.from_json_keyfile_name("/tmp/service_account.json", scope)
    client = gspread.authorize(creds)
    ws = client.open_by_url(GOOGLE_SHEET_URL).worksheet(sheet_name)
    df = pd.DataFrame(ws.get_all_records())
    df.columns = [c.lower().strip() for c in df.columns]
    return df

STYLE_RE = re.compile(r"\b([A-Z]{1,3}\d{3,5}[A-Z0-9]?)\b")

def parse_temudate(x):
    s = str(x)
    if "(" in s:
        s = s.split("(")[0].strip()
    try:
        return parser.parse(s, fuzzy=True)
    except Exception:
        return pd.NaT

def parse_sheindate(x):
    try:
        return pd.to_datetime(str(x), errors="coerce", infer_datetime_format=True)
    except Exception:
        return pd.NaT


def build_img_map(df_info: pd.DataFrame):
    keys = df_info.get("product number", pd.Series(dtype=str)).astype(str).str.upper().str.replace(" ", "", regex=False)
    return dict(zip(keys, df_info.get("image", "")))


def style_key_from_label(label: str, img_map: dict) -> str | None:
    s = str(label).strip().upper()
    if not s:
        return None
    s_key = s.replace(" ", "")
    if s_key in img_map:
        return s_key
    m = STYLE_RE.search(s)
    if m:
        cand = m.group(1).replace(" ", "")
        if cand in img_map:
            return cand
    for k in img_map.keys():
        if k in s_key:
            return k
    return None


def usd(x):
    try:
        v = float(x)
        return f"${v:,.2f}"
    except Exception:
        return "-"

# -------------------------
# Load & Normalize
# -------------------------
df_info = load_google_sheet("PRODUCT_INFO")
df_temu = load_google_sheet("TEMU_SALES")
df_shein = load_google_sheet("SHEIN_SALES")

IMG_MAP = build_img_map(df_info)

# Dates

df_temu["order date"] = df_temu["purchase date"].apply(parse_temudate)
df_shein["order date"] = df_shein["order processed on"].apply(parse_sheindate)

# Status & numeric

df_temu["order item status"] = df_temu["order item status"].astype(str)
df_temu["quantity shipped"] = pd.to_numeric(df_temu.get("quantity shipped", 0), errors="coerce").fillna(0)

df_shein["order status"] = df_shein["order status"].astype(str)
df_shein["product price"] = (
    df_shein["product price"].astype(str).str.replace(r"[^0-9.\-]", "", regex=True).replace("", pd.NA).astype(float)
)

# -------------------------
# Date controls
# -------------------------
min_dt = pd.to_datetime(pd.concat([
    df_temu["order date"], df_shein["order date"]
]).dropna()).min()
max_dt = pd.to_datetime(pd.concat([
    df_temu["order date"], df_shein["order date"]
]).dropna()).max()

if pd.isna(min_dt) or pd.isna(max_dt):
    st.info("ë‚ ì§œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì‹œíŠ¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

c1, c2 = st.columns([1, 9])
with c1:
    st.caption("ì¡°íšŒ ê¸°ê°„")
with c2:
    dr = st.date_input(
        "", value=(max_dt.date() - pd.Timedelta(days=29), max_dt.date()), min_value=min_dt.date(), max_value=max_dt.date()
    )
    if isinstance(dr, (list, tuple)):
        start, end = dr
    else:
        start = end = dr
    start = pd.to_datetime(start)
    end = pd.to_datetime(end) + pd.Timedelta(hours=23, minutes=59, seconds=59)

# -------------------------
# Aggregate per platform
# -------------------------
# TEMU: shipped/delivered only
_t = df_temu[(df_temu["order date"] >= start) & (df_temu["order date"] <= end)].copy()
_t = _t[_t["order item status"].str.lower().isin(["shipped", "delivered"])].copy()
_t["style_key"] = _t["product number"].astype(str).apply(lambda x: style_key_from_label(x, IMG_MAP))
_t = _t.dropna(subset=["style_key"]) 

temu_grp = _t.groupby("style_key").agg(
    temu_qty=("quantity shipped", "sum"),
    temu_sales=("base price total", lambda s: pd.to_numeric(s.astype(str).str.replace(r"[^0-9.\-]", "", regex=True), errors="coerce").fillna(0).sum()),
)
temu_grp["temu_aov"] = temu_grp.apply(lambda r: (r["temu_sales"] / r["temu_qty"]) if r["temu_qty"] > 0 else 0.0, axis=1)

# SHEIN: exclude customer refunded
_s = df_shein[(df_shein["order date"] >= start) & (df_shein["order date"] <= end)].copy()
_s = _s[~_s["order status"].str.lower().isin(["customer refunded"])].copy()
_s["style_key"] = _s["product description"].astype(str).apply(lambda x: style_key_from_label(x, IMG_MAP))
_s = _s.dropna(subset=["style_key"]).copy()

shein_grp = _s.groupby("style_key").agg(
    shein_qty=("product description", "count"),
    shein_sales=("product price", "sum"),
)
shein_grp["shein_aov"] = shein_grp.apply(lambda r: (r["shein_sales"] / r["shein_qty"]) if r["shein_qty"] > 0 else 0.0, axis=1)

# Merge (styles present in either)
combined = pd.concat([temu_grp, shein_grp], axis=1).fillna(0.0)
combined = combined.reset_index().rename(columns={"index": "style_key", "style_key": "Style Number"})

# Strength tag
STR_Q = 1.3  # 30% ì´ìƒ ìš°ìœ„ë©´ ê°•ì„¸ íƒœê·¸

def tag_strength(r):
    if r["temu_qty"] >= r["shein_qty"] * STR_Q and r["temu_qty"] >= 3:
        return "TEMU ê°•ì„¸"
    if r["shein_qty"] >= r["temu_qty"] * STR_Q and r["shein_qty"] >= 3:
        return "SHEIN ê°•ì„¸"
    return "ê· í˜•"

combined["íƒœê·¸"] = combined.apply(tag_strength, axis=1)

# Image column
img_map = IMG_MAP
combined["ì´ë¯¸ì§€"] = combined["Style Number"].apply(lambda x: f"<img src='{img_map.get(str(x).upper(), '')}' class='thumb'>" if str(img_map.get(str(x).upper(), '')).startswith("http") else "")

# Display KPIs
with st.container(border=True):
    st.markdown("**ìš”ì•½**")
    cols = st.columns(4)
    both_styles = ((combined["temu_qty"] > 0) & (combined["shein_qty"] > 0)).sum()
    temu_strong = (combined["íƒœê·¸"] == "TEMU ê°•ì„¸").sum()
    shein_strong = (combined["íƒœê·¸"] == "SHEIN ê°•ì„¸").sum()
    total_styles = combined.shape[0]
    with cols[0]:
        st.metric("ë¶„ì„ ìŠ¤íƒ€ì¼ ìˆ˜", f"{total_styles:,}")
    with cols[1]:
        st.metric("ì–‘ í”Œë«í¼ ë™ì‹œ íŒë§¤", f"{both_styles:,}")
    with cols[2]:
        st.metric("TEMU ê°•ì„¸", f"{temu_strong:,}")
    with cols[3]:
        st.metric("SHEIN ê°•ì„¸", f"{shein_strong:,}")

# Action heuristic

def action_hint(row):
    if row["íƒœê·¸"] == "TEMU ê°•ì„¸":
        return "SHEIN ë…¸ì¶œ/ê°€ê²© ì ê²€ (ì´ë¯¸ì§€Â·íƒ€ì´í‹€ ê°œì„  + ì†Œí­ í• ì¸ ê²€í† )"
    if row["íƒœê·¸"] == "SHEIN ê°•ì„¸":
        return "TEMU ê°€ê²© ì¬ê²€í†  ë˜ëŠ” ë…¸ì¶œ ê°•í™” (í‚¤ì›Œë“œ/ì´ë¯¸ì§€ ê°œì„ )"
    return "ë‘ í”Œë«í¼ ë™ì¼ ì „ëµ ìœ ì§€"

combined["ì•¡ì…˜"] = combined.apply(action_hint, axis=1)

# Sorting option
sort_opt = st.selectbox(
    "ì •ë ¬ ê¸°ì¤€",
    ["ì´ íŒë§¤ìˆ˜ëŸ‰", "í”Œë«í¼ ê²©ì°¨(QTY)", "í”Œë«í¼ ê²©ì°¨(AOV)", "í”Œë«í¼ ê²©ì°¨(ë§¤ì¶œ)", "Style Number"],
    index=0,
)

combined["ì´í•©_qty"] = combined["temu_qty"] + combined["shein_qty"]
combined["ê²©ì°¨_qty"] = (combined["temu_qty"] - combined["shein_qty"]).abs()
combined["ê²©ì°¨_aov"] = (combined["temu_aov"] - combined["shein_aov"]).abs()
combined["ê²©ì°¨_sales"] = (combined["temu_sales"] - combined["shein_sales"]).abs()

if sort_opt == "ì´ íŒë§¤ìˆ˜ëŸ‰":
    combined = combined.sort_values("ì´í•©_qty", ascending=False)
elif sort_opt == "í”Œë«í¼ ê²©ì°¨(QTY)":
    combined = combined.sort_values("ê²©ì°¨_qty", ascending=False)
elif sort_opt == "í”Œë«í¼ ê²©ì°¨(AOV)":
    combined = combined.sort_values("ê²©ì°¨_aov", ascending=False)
elif sort_opt == "í”Œë«í¼ ê²©ì°¨(ë§¤ì¶œ)":
    combined = combined.sort_values("ê²©ì°¨_sales", ascending=False)
else:
    combined = combined.sort_values("Style Number")

# Pretty format
show = combined[[
    "ì´ë¯¸ì§€", "Style Number",
    "temu_qty", "temu_sales", "temu_aov",
    "shein_qty", "shein_sales", "shein_aov",
    "íƒœê·¸", "ì•¡ì…˜"
]].copy()

show.rename(columns={
    "temu_qty": "TEMU Qty", "temu_sales": "TEMU Sales", "temu_aov": "TEMU AOV",
    "shein_qty": "SHEIN Qty", "shein_sales": "SHEIN Sales", "shein_aov": "SHEIN AOV",
}, inplace=True)

for col in ["TEMU Sales", "TEMU AOV", "SHEIN Sales", "SHEIN AOV"]:
    show[col] = show[col].apply(usd)

st.markdown("""
<style>
img.thumb { width:72px; height:auto; border-radius:10px; }
.table-wrap table { width:100% !important; border-collapse:separate; border-spacing:0; }
.table-wrap th, .table-wrap td { padding:10px 12px; font-size:0.95rem; }
.table-wrap thead th { background:#fafafa; position:sticky; top:0; z-index:1; }
</style>
""", unsafe_allow_html=True)

with st.container(border=True):
    st.markdown("**í”Œë«í¼ë³„ ì„±ê³¼ ë¹„êµ í…Œì´ë¸”**")
    st.markdown(f"<div class='table-wrap'>{show.to_html(escape=False, index=False)}</div>", unsafe_allow_html=True)

# Download
csv = combined.to_csv(index=False)
st.download_button("CSV ë‹¤ìš´ë¡œë“œ", data=csv, file_name="cross_platform_compare.csv", mime="text/csv")


# ==========================================
# File: pages/6_ë°˜í’ˆ_ì·¨ì†Œìœ¨.py
# ==========================================
import streamlit as st
import pandas as pd
from dateutil import parser

st.set_page_config(page_title="ë°˜í’ˆÂ·ì·¨ì†Œìœ¨ ë¶„ì„", layout="wide")
st.title("â†©ï¸ ë°˜í’ˆÂ·ì·¨ì†Œìœ¨ ë¶„ì„")

@st.cache_data(show_spinner=False)
def load_google_sheet(sheet_name: str) -> pd.DataFrame:
    import gspread
    from oauth2client.service_account import ServiceAccountCredentials
    import json
    GOOGLE_SHEET_URL = "https://docs.google.com/spreadsheets/d/1oyVzCgGK1Q3Qi_sbYwE-wKG6SArnfUDRe7rQfGOF-Eo"
    scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
    creds_json = {k: str(v) for k, v in st.secrets["gcp_service_account"].items()}
    with open("/tmp/service_account.json", "w") as f:
        import json as _json
        _json.dump(creds_json, f)
    creds = ServiceAccountCredentials.from_json_keyfile_name("/tmp/service_account.json", scope)
    client = gspread.authorize(creds)
    ws = client.open_by_url(GOOGLE_SHEET_URL).worksheet(sheet_name)
    df = pd.DataFrame(ws.get_all_records())
    df.columns = [c.lower().strip() for c in df.columns]
    return df

def parse_temudate(x):
    try:
        s = str(x).split("(")[0].strip()
        return parser.parse(s, fuzzy=True)
    except Exception:
        return pd.NaT

def parse_sheindate(x):
    try:
        return pd.to_datetime(str(x), errors='coerce', infer_datetime_format=True)
    except Exception:
        return pd.NaT

# Load
info = load_google_sheet("PRODUCT_INFO")
temu = load_google_sheet("TEMU_SALES")
shein = load_google_sheet("SHEIN_SALES")

# Dates & normalization

temu["order date"] = temu["purchase date"].apply(parse_temudate)
temu["order item status"] = temu["order item status"].astype(str)
temu["quantity shipped"] = pd.to_numeric(temu.get("quantity shipped", 0), errors="coerce").fillna(0)
temu["quantity purchased"] = pd.to_numeric(temu.get("quantity purchased", 0), errors="coerce").fillna(0)

shein["order date"] = shein["order processed on"].apply(parse_sheindate)
shein["order status"] = shein["order status"].astype(str)

min_dt = pd.to_datetime(pd.concat([temu["order date"], shein["order date"]]).dropna()).min()
max_dt = pd.to_datetime(pd.concat([temu["order date"], shein["order date"]]).dropna()).max()

if pd.isna(min_dt) or pd.isna(max_dt):
    st.info("ë‚ ì§œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

c1, c2, c3 = st.columns([5, 3, 2])
with c1:
    dr = st.date_input(
        "ì¡°íšŒ ê¸°ê°„",
        value=(max_dt.date() - pd.Timedelta(days=29), max_dt.date()),
        min_value=min_dt.date(), max_value=max_dt.date()
    )
    if isinstance(dr, (list, tuple)):
        start, end = dr
    else:
        start = end = dr
    start = pd.to_datetime(start)
    end = pd.to_datetime(end) + pd.Timedelta(hours=23, minutes=59, seconds=59)
with c2:
    min_order = st.number_input("ìµœì†Œ ì£¼ë¬¸ ê¸°ì¤€(ë…¸ì´ì¦ˆ ì œê±°)", min_value=1, max_value=100, value=5, step=1)
with c3:
    st.markdown("\n")
    st.caption("*ì·¨ì†Œìœ¨ = (ì·¨ì†Œ/í™˜ë¶ˆ) Ã· (ì¶œê³ +ì·¨ì†Œ)*")

# Platform aggregates
# TEMU
T = temu[(temu["order date"] >= start) & (temu["order date"] <= end)].copy()
T_status = T["order item status"].str.lower()
T_ship = T[T_status.isin(["shipped", "delivered"])].copy()
T_cancel = T[T_status.eq("canceled")].copy()

T_ship_qty = T_ship.groupby("product number")["quantity shipped"].sum()
T_cancel_qty = T_cancel.groupby("product number")["quantity purchased"].sum()

T_all = pd.concat([T_ship_qty, T_cancel_qty], axis=1).fillna(0)
T_all.columns = ["shipped_qty", "canceled_qty"]
T_all["orders_total"] = T_all["shipped_qty"] + T_all["canceled_qty"]
T_all["cancel_rate"] = T_all.apply(lambda r: (r["canceled_qty"] / r["orders_total"]) if r["orders_total"] > 0 else 0.0, axis=1)
T_all.index.name = "Style Number"

# SHEIN
S = shein[(shein["order date"] >= start) & (shein["order date"] <= end)].copy()
S_status = S["order status"].str.lower()
S_sold = S[~S_status.isin(["customer refunded"])].copy()
S_ref = S[S_status.isin(["customer refunded"])].copy()

S_sold_cnt = S_sold.groupby("product description").size()
S_ref_cnt = S_ref.groupby("product description").size()

S_all = pd.concat([S_sold_cnt, S_ref_cnt], axis=1).fillna(0)
S_all.columns = ["sold_cnt", "refunded_cnt"]
S_all["orders_total"] = S_all["sold_cnt"] + S_all["refunded_cnt"]
S_all["cancel_rate"] = S_all.apply(lambda r: (r["refunded_cnt"] / r["orders_total"]) if r["orders_total"] > 0 else 0.0, axis=1)
S_all.index.name = "Style Number"

# KPI
with st.container(border=True):
    cols = st.columns(4)
    with cols[0]:
        st.metric("TEMU ì „ì²´ ì·¨ì†Œìœ¨", f"{(T_all['canceled_qty'].sum() / max(T_all['orders_total'].sum(),1))*100:,.1f}%")
    with cols[1]:
        st.metric("SHEIN ì „ì²´ í™˜ë¶ˆìœ¨", f"{(S_all['refunded_cnt'].sum() / max(S_all['orders_total'].sum(),1))*100:,.1f}%")
    with cols[2]:
        st.metric("TEMU ë¶„ì„ ìŠ¤íƒ€ì¼ ìˆ˜", f"{(T_all['orders_total']>=min_order).sum():,}")
    with cols[3]:
        st.metric("SHEIN ë¶„ì„ ìŠ¤íƒ€ì¼ ìˆ˜", f"{(S_all['orders_total']>=min_order).sum():,}")

# High rate tables
thr_temu = st.slider("TEMU ì·¨ì†Œìœ¨ ê²½ê³  ì„ê³„ê°’", 0.0, 1.0, 0.25, 0.05)
thr_shein = st.slider("SHEIN í™˜ë¶ˆìœ¨ ê²½ê³  ì„ê³„ê°’", 0.0, 1.0, 0.20, 0.05)

T_tbl = T_all[(T_all["orders_total"] >= min_order) & (T_all["cancel_rate"] >= thr_temu)].copy()
S_tbl = S_all[(S_all["orders_total"] >= min_order) & (S_all["cancel_rate"] >= thr_shein)].copy()

# Formatting
T_tbl = T_tbl.reset_index()
S_tbl = S_tbl.reset_index()

T_tbl["ì·¨ì†Œìœ¨"] = (T_tbl["cancel_rate"] * 100).round(1).astype(str) + "%"
S_tbl["í™˜ë¶ˆìœ¨"] = (S_tbl["cancel_rate"] * 100).round(1).astype(str) + "%"

# Output
left, right = st.columns(2)
with left:
    st.subheader("TEMU â€“ ì·¨ì†Œìœ¨ ë†’ì€ ìŠ¤íƒ€ì¼")
    if T_tbl.empty:
        st.info("ì„ê³„ê°’ì„ ì¶©ì¡±í•˜ëŠ” ìŠ¤íƒ€ì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.dataframe(T_tbl[["Style Number", "shipped_qty", "canceled_qty", "orders_total", "ì·¨ì†Œìœ¨"]].sort_values("cancel_rate", ascending=False), use_container_width=True)

with right:
    st.subheader("SHEIN â€“ í™˜ë¶ˆìœ¨ ë†’ì€ ìŠ¤íƒ€ì¼")
    if S_tbl.empty:
        st.info("ì„ê³„ê°’ì„ ì¶©ì¡±í•˜ëŠ” ìŠ¤íƒ€ì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.dataframe(S_tbl[["Style Number", "sold_cnt", "refunded_cnt", "orders_total", "í™˜ë¶ˆìœ¨"]].sort_values("cancel_rate", ascending=False), use_container_width=True)

st.caption("ì°¸ê³ : TEMUëŠ” 'canceled'ë¥¼ ì·¨ì†Œë¡œ, SHEINì€ 'customer refunded'ë¥¼ í™˜ë¶ˆë¡œ ì§‘ê³„í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì‚¬ìœ ì½”ë“œê°€ ìˆì„ ê²½ìš° ì‹œíŠ¸ ì»¬ëŸ¼ ê¸°ì¤€ìœ¼ë¡œ ì¶”ê°€ í™•ì¥ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
